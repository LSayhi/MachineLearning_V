{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于概率论的分类方法：朴素贝叶斯\n",
    "\n",
    "   ### 优点：在数据较少的情况下仍然有效，可以处理多类别问题。\n",
    "\n",
    "   ### 缺点：对于输入数据的准备方式较为敏感。\n",
    "\n",
    "   ### 适用数据类型：标称型数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### 条件概率：p(c|x)*p(x)=p(x|c)*p(c)\n",
    "\n",
    "贝叶斯决策理论的核心思想：选择具有最高概率的决策。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 使用python进行文本分类\n",
    "\n",
    "要从文本中获取特征，需要先拆分文本。把每一个文本片段表示为一个词条向量，其中值为1表示词条出现在文档中，0表示词条未出现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 准备数据：从文本中构建词向量。\n",
    "\n",
    "创建bayes.py文件，添加代码 4-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listOPosts,listClasses = bayes.loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myVocabList = bayes.createVocabList(listOPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cute',\n",
       " 'love',\n",
       " 'help',\n",
       " 'garbage',\n",
       " 'quit',\n",
       " 'I',\n",
       " 'problems',\n",
       " 'is',\n",
       " 'park',\n",
       " 'stop',\n",
       " 'flea',\n",
       " 'dalmation',\n",
       " 'licks',\n",
       " 'food',\n",
       " 'not',\n",
       " 'him',\n",
       " 'buying',\n",
       " 'posting',\n",
       " 'has',\n",
       " 'worthless',\n",
       " 'ate',\n",
       " 'to',\n",
       " 'maybe',\n",
       " 'please',\n",
       " 'dog',\n",
       " 'how',\n",
       " 'stupid',\n",
       " 'so',\n",
       " 'take',\n",
       " 'sotp',\n",
       " 'mr',\n",
       " 'steak',\n",
       " 'my',\n",
       " 'dot']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myVocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.setOfWords2Vec(myVocabList,listOPosts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes.setOfWords2Vec(myVocabList,listOPosts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2  训练算法：从词向量计算概率\n",
    "\n",
    "伪代码：\n",
    "\n",
    "计算每个类别中的文档数目\n",
    "\n",
    "对每篇训练文档：\n",
    "\n",
    "    对每个类别：\n",
    "        如果词条出现在文档中：增加该词条的计数值\n",
    "        增加所有词条的计数值\n",
    "对每个类别：\n",
    "\n",
    "    对每个词条：\n",
    "        将该词条的数目除以总词条数目得到条件概率\n",
    "        \n",
    "返回每个类别的条件概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在bayes.py中添加代码：4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bayes\n",
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#生成数据集和标签列表\n",
    "listOPosts,listClass = bayes.loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从文本中构建词向量列表\n",
    "myVocabList = bayes.createVocabList(listOPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#新建一个空集合，用来存放文本所转换的文档向量。[1,0,0,1...]\n",
    "trainMat = []\n",
    "for postinDoc in listOPosts:\n",
    "    trainMat.append(bayes.setOfWords2Vec(myVocabList,postinDoc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p0V,p1V,pAb = bayes._trainNB0(trainMat,listClass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任意文档属于侮辱性文档的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pAb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常文档中每个单词出现的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04166667,  0.04166667,  0.04166667,  0.        ,  0.        ,\n",
       "        0.04166667,  0.04166667,  0.04166667,  0.        ,  0.04166667,\n",
       "        0.04166667,  0.04166667,  0.04166667,  0.        ,  0.        ,\n",
       "        0.08333333,  0.        ,  0.        ,  0.04166667,  0.        ,\n",
       "        0.04166667,  0.04166667,  0.        ,  0.04166667,  0.04166667,\n",
       "        0.04166667,  0.        ,  0.04166667,  0.        ,  0.        ,\n",
       "        0.04166667,  0.04166667,  0.125     ,  0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "侮辱性文档中每个单词出现的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.05263158,  0.05263158,\n",
       "        0.        ,  0.        ,  0.        ,  0.05263158,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.05263158,  0.05263158,\n",
       "        0.05263158,  0.05263158,  0.05263158,  0.        ,  0.10526316,\n",
       "        0.        ,  0.05263158,  0.05263158,  0.        ,  0.05263158,\n",
       "        0.        ,  0.15789474,  0.        ,  0.05263158,  0.05263158,\n",
       "        0.        ,  0.        ,  0.        ,  0.05263158])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.1.3 测试算法：根据现实情况修改分类器\n",
    "\n",
    "1.利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，既计算p(w0|1)*p(w1|1)...\n",
    "如果其中一个概率值为0，那么最后的乘积也为0，为降低这种影响，可以将所有词的出现数初始化为1，并将分母初始化为2.\n",
    "\n",
    "2.另一个问题是下溢出，这是由于太多很小的数相乘造成。python会四舍五入。所以在最后返回时用ln(f(x))代替f(x)\n",
    "\n",
    "训练数据优化版本：代码4-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3.现在已经准备好构建完整的分类器来。代码4-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['love', 'my', 'dalmation'], 'classified as:', 0)\n",
      "(['stupid', 'garbage'], 'classified as:', 1)\n"
     ]
    }
   ],
   "source": [
    "reload(bayes)\n",
    "bayes.testingNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1.4 准备数据： 文档词袋模型\n",
    "\n",
    "到目前为止，我们将每个词的出现与否作为一个特征，这被称为“词集模型”。如果一个词在文档中出现不止一次，这可能意味着包含该词是否出现在文档中所不能表达的某种信息，这种方法被称为“词袋模型”.在词袋中，每个单词可以出现多次，而在词集中，每个词只能出现一次。为适应词袋模型，需要对函数setOfWords2Vec()修改。修改后的函数为bagOfWords2Vec()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯词袋模型：添加代码4-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 示例：使用朴素贝叶斯过滤垃圾邮件\n",
    "\n",
    "1.收集数据：提供文本文件。\n",
    "\n",
    "2.准备数据：将文本文件解析成词条向量。\n",
    "\n",
    "3.分析数据：检查词条确保解析的正确性。\n",
    "\n",
    "4.训练算法：使用我们之前建立的trainNB0()函数。\n",
    "\n",
    "5.测试算法：使用classifyNB().并且构建一个新的测试函数来计算文档集的错误率。\n",
    "\n",
    "6.使用算法：构建一个完整的程序对一组文档进行分类，将错分的文档输出到屏幕上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 准备数据：切分文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个文本字符串，可以使用python的string.split()方法将其划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'ML',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySent='This book is the best book on Python or ML I have ever laid eyes upon.'\n",
    "mySent.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看见，虽然切分的不错，但是标点符号也被当成词的一部分。可以使用正则表达式来切分句子。\n",
    "\n",
    "其中分隔符是除单词，数字外的任意字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'ML',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon',\n",
       " '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "regEx = re.compile('\\\\W*')\n",
    "listOfTokens = regEx.split(mySent)\n",
    "listOfTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在得到了一系列词组成的词表，但是空字符串也在里面。可以通过判断每个字符串的长度筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'Python',\n",
       " 'or',\n",
       " 'ML',\n",
       " 'I',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok for tok in listOfTokens if len(tok)>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这我们发现句子中的第一个单词是大写的。如果目的是句子查找，那么这个特点会很有用。但这里的文本只是看成词袋，所以我们需要所有词的形式都是统一的。\n",
    "\n",
    "python中有一些内嵌的方法，可以将字符串全部转换成小写（.lower()）或者大写（.upper()）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'book',\n",
       " 'on',\n",
       " 'python',\n",
       " 'or',\n",
       " 'ml',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'laid',\n",
       " 'eyes',\n",
       " 'upon']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok.lower() for tok in listOfTokens if len(tok)>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 测试算法：使用朴素贝叶斯进行交叉验证\n",
    "\n",
    "下面将文本解析器集成到一个完整分类器中。\n",
    "\n",
    "在bayes.py中添加代码4-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试代码运行，每次结果有差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the error rate is :', 0.0)\n"
     ]
    }
   ],
   "source": [
    "reload(bayes)\n",
    "bayes.spamTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the error rate is :', 0.2)\n"
     ]
    }
   ],
   "source": [
    "bayes.spamTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the error rate is :', 0.1)\n"
     ]
    }
   ],
   "source": [
    "bayes.spamTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  4.3 示例：使用朴素贝叶斯分类器从个人广告中获取区域倾向\n",
    "\n",
    "1.收集数据：从RSS源收集内容，这里需要对RSS源构建一个接口。\n",
    "\n",
    "2.准备数据：将文本文将解析成词条向量。\n",
    "\n",
    "3.分析数据：检查词条确保解析的正确性。\n",
    "\n",
    "4.训练算法：使用我们之前建立的trainNB0()函数。\n",
    "\n",
    "5.测试算法：观察错误率，确保分类器可用，可用修改切分程序，以降低错误率，提高分类结果。\n",
    "\n",
    "6.使用算法： 构建一个完整的程序，封装所有内容。给定两个RSS源,该程序会显示最常用的公共词。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 收集数据：导入RSS源\n",
    "\n",
    " 首先需要使用python下载文本。利用RSS，在官方下载feedparse安装包，然后正常安装解压。\n",
    " \n",
    " python setup.py install\n",
    " \n",
    " 下面使用Craigslist上的个人广告测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "ny = feedparser.parse('http://newyork.craigslist.org/stp/index.rss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ny['entries'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在在bayes.py中添加代码4-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'bayes' from 'bayes.pyc'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bayes\n",
    "reload(bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny = feedparser.parse('http://newyork.craigslist.org/stp/index.rss')\n",
    "sf = feedparser.parse('http://sfbay.craigslist.org/stp/index.rss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('teh error rate is :', 0.55)\n"
     ]
    }
   ],
   "source": [
    "reload(bayes)\n",
    "vocabList,pSF,pNY = bayes.localWords(ny,sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('teh error rate is :', 0.4)\n"
     ]
    }
   ],
   "source": [
    "vocabList,pSF,pNY = bayes.localWords(ny,sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('teh error rate is :', 0.35)\n"
     ]
    }
   ],
   "source": [
    "vocabList,pSF,pNY = bayes.localWords(ny,sf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
